Sender: LSF System <lsfadmin@compute-0-130>
Subject: Job 638615: <Teddy-MPI> in cluster <mghpcc_cluster1> Done

Job <Teddy-MPI> was submitted from host <discovery2> by user <stoddard.t> in cluster <mghpcc_cluster1>.
Job was executed on host(s) <4*compute-0-130>, in queue <ser-par-10g-3>, as user <stoddard.t> in cluster <mghpcc_cluster1>.
</home/stoddard.t> was used as the home directory.
</home/stoddard.t/FibonacciSphere> was used as the working directory.
Started at Wed Apr 13 09:27:37 2016
Results reported at Wed Apr 13 09:28:01 2016

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
#BSUB -J Teddy-MPI
#BSUB -o project_output_file
#BSUB -e project_error_file
#BSUB -n 4
#BSUB -q ser-par-10g-3
#BSUB cwd /home/stoddard.t/FibonacciSphere/
#BSUB -R "span[ptile=4]"
work=/home/stoddard.t/FibonacciSphere/

cd $work
tempfile1=hostlistrun
tempfile2=hostlist-tcp
echo $LSB_MCPU_HOSTS > $tempfile1
declare -a hosts
read -a hosts < ${tempfile1}
for ((i=0; i<${#hosts[@]}; i += 2)) ;
do
  HOST=${hosts[$i]}
  CORE=${hosts[(($i+1))]}
  echo $HOST:$CORE >> $tempfile2
done

mpirun -np 4 -prot -TCP -lsf ./bin/fibonacciSphereMPI 1000000 10000000 123456789

rm $work/$tempfile1
rm $work/$tempfile2
 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :               75.31 sec.
    Max Memory :             14 MB
    Average Memory :         14.00 MB
    Total Requested Memory : -
    Delta Memory :           -
    (Delta: the difference between total requested memory and actual max usage.)
    Max Swap :               57 MB

    Max Processes :          1
    Max Threads :            1

The output (if any) follows:

Host 0 -- ip 10.100.9.87 -- ranks 0 - 3

 host | 0
======|======
    0 : SHM

 Prot -  All Intra-node communication is: SHM

Bins: 1000000
Points: 10000000
Nodes: 4
Seed: 123456789
maxLocalNumPoints: 2500000
Rank: 2 Bad Points:2

Timing:
Point Generation: 3.089135
Map Generation: 0.019302
Point Binning: 15.686617


PS:

Read file <project_error_file> for stderr output of this job.

Sender: LSF System <lsfadmin@compute-0-131>
Subject: Job 638616: <Teddy-MPI> in cluster <mghpcc_cluster1> Done

Job <Teddy-MPI> was submitted from host <discovery2> by user <stoddard.t> in cluster <mghpcc_cluster1>.
Job was executed on host(s) <4*compute-0-131>, in queue <ser-par-10g-3>, as user <stoddard.t> in cluster <mghpcc_cluster1>.
</home/stoddard.t> was used as the home directory.
</home/stoddard.t/FibonacciSphere> was used as the working directory.
Started at Wed Apr 13 09:28:11 2016
Results reported at Wed Apr 13 09:28:36 2016

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
#BSUB -J Teddy-MPI
#BSUB -o project_output_file
#BSUB -e project_error_file
#BSUB -n 4
#BSUB -q ser-par-10g-3
#BSUB cwd /home/stoddard.t/FibonacciSphere/
#BSUB -R "span[ptile=4]"
work=/home/stoddard.t/FibonacciSphere/

cd $work
tempfile1=hostlistrun
tempfile2=hostlist-tcp
echo $LSB_MCPU_HOSTS > $tempfile1
declare -a hosts
read -a hosts < ${tempfile1}
for ((i=0; i<${#hosts[@]}; i += 2)) ;
do
  HOST=${hosts[$i]}
  CORE=${hosts[(($i+1))]}
  echo $HOST:$CORE >> $tempfile2
done

mpirun -np 4 -prot -TCP -lsf ./bin/fibonacciSphereMPI 1000000 10000000 123456789

rm $work/$tempfile1
rm $work/$tempfile2
 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :               75.51 sec.
    Max Memory :             14 MB
    Average Memory :         14.00 MB
    Total Requested Memory : -
    Delta Memory :           -
    (Delta: the difference between total requested memory and actual max usage.)
    Max Swap :               57 MB

    Max Processes :          1
    Max Threads :            1

The output (if any) follows:

Host 0 -- ip 10.100.9.88 -- ranks 0 - 3

 host | 0
======|======
    0 : SHM

 Prot -  All Intra-node communication is: SHM

Bins: 1000000
Points: 10000000
Nodes: 4
Seed: 123456789
maxLocalNumPoints: 2500000
Rank: 2 Bad Points:2

Timing:
Point Generation: 3.098517
Map Generation: 0.019524
Point Binning: 15.707544


PS:

Read file <project_error_file> for stderr output of this job.

Sender: LSF System <lsfadmin@compute-0-132>
Subject: Job 638617: <Teddy-MPI> in cluster <mghpcc_cluster1> Done

Job <Teddy-MPI> was submitted from host <discovery2> by user <stoddard.t> in cluster <mghpcc_cluster1>.
Job was executed on host(s) <4*compute-0-132>, in queue <ser-par-10g-3>, as user <stoddard.t> in cluster <mghpcc_cluster1>.
                            <4*compute-0-134>
                            <4*compute-0-135>
                            <4*compute-0-136>
</home/stoddard.t> was used as the home directory.
</home/stoddard.t/FibonacciSphere> was used as the working directory.
Started at Wed Apr 13 09:28:56 2016
Results reported at Wed Apr 13 09:29:11 2016

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
#BSUB -J Teddy-MPI
#BSUB -o project_output_file
#BSUB -e project_error_file
#BSUB -n 16
#BSUB -q ser-par-10g-3
#BSUB cwd /home/stoddard.t/FibonacciSphere/
#BSUB -R "span[ptile=4]"
work=/home/stoddard.t/FibonacciSphere/

cd $work
tempfile1=hostlistrun
tempfile2=hostlist-tcp
echo $LSB_MCPU_HOSTS > $tempfile1
declare -a hosts
read -a hosts < ${tempfile1}
for ((i=0; i<${#hosts[@]}; i += 2)) ;
do
  HOST=${hosts[$i]}
  CORE=${hosts[(($i+1))]}
  echo $HOST:$CORE >> $tempfile2
done

mpirun -np 16 -prot -TCP -lsf ./bin/fibonacciSphereMPI 1000000 10000000 123456789

rm $work/$tempfile1
rm $work/$tempfile2
 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :               122.20 sec.
    Max Memory :             13 MB
    Average Memory :         13.00 MB
    Total Requested Memory : -
    Delta Memory :           -
    (Delta: the difference between total requested memory and actual max usage.)
    Max Swap :               56 MB

    Max Processes :          1
    Max Threads :            1

The output (if any) follows:

Host 0 -- ip 10.100.9.89 -- ranks 0 - 3
Host 1 -- ip 10.100.9.91 -- ranks 4 - 7
Host 2 -- ip 10.100.9.92 -- ranks 8 - 11
Host 3 -- ip 10.100.9.93 -- ranks 12 - 15

 host | 0    1    2    3
======|=====================
    0 : SHM  TCP  TCP  TCP
    1 : TCP  SHM  TCP  TCP
    2 : TCP  TCP  SHM  TCP
    3 : TCP  TCP  TCP  SHM

 Prot -  All Intra-node communication is: SHM
 Prot -  All Inter-node communication is: TCP

Bins: 1000000
Points: 10000000
Nodes: 16
Seed: 123456789
maxLocalNumPoints: 625000
Rank: 8 Bad Points:1

Timing:
Point Generation: 3.178480
Map Generation: 0.019398
Point Binning: 3.941539
Rank: 10 Bad Points:1


PS:

Read file <project_error_file> for stderr output of this job.

Sender: LSF System <lsfadmin@compute-0-130>
Subject: Job 638618: <Teddy-MPI> in cluster <mghpcc_cluster1> Done

Job <Teddy-MPI> was submitted from host <discovery2> by user <stoddard.t> in cluster <mghpcc_cluster1>.
Job was executed on host(s) <4*compute-0-130>, in queue <ser-par-10g-3>, as user <stoddard.t> in cluster <mghpcc_cluster1>.
                            <4*compute-0-137>
                            <4*compute-0-138>
                            <4*compute-0-139>
                            <4*compute-0-100>
                            <4*compute-0-104>
                            <4*compute-0-106>
                            <4*compute-0-107>
</home/stoddard.t> was used as the home directory.
</home/stoddard.t/FibonacciSphere> was used as the working directory.
Started at Wed Apr 13 09:32:02 2016
Results reported at Wed Apr 13 09:32:28 2016

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
#BSUB -J Teddy-MPI
#BSUB -o project_output_file
#BSUB -e project_error_file
#BSUB -n 32
#BSUB -q ser-par-10g-3
#BSUB cwd /home/stoddard.t/FibonacciSphere/
#BSUB -R "span[ptile=4]"
work=/home/stoddard.t/FibonacciSphere/

cd $work
tempfile1=hostlistrun
tempfile2=hostlist-tcp
echo $LSB_MCPU_HOSTS > $tempfile1
declare -a hosts
read -a hosts < ${tempfile1}
for ((i=0; i<${#hosts[@]}; i += 2)) ;
do
  HOST=${hosts[$i]}
  CORE=${hosts[(($i+1))]}
  echo $HOST:$CORE >> $tempfile2
done

mpirun -np 32 -prot -TCP -lsf ./bin/fibonacciSphereMPI 1000000 10000000 123456789

rm $work/$tempfile1
rm $work/$tempfile2
 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :               279.08 sec.
    Max Memory :             14 MB
    Average Memory :         14.00 MB
    Total Requested Memory : -
    Delta Memory :           -
    (Delta: the difference between total requested memory and actual max usage.)
    Max Swap :               57 MB

    Max Processes :          1
    Max Threads :            1

The output (if any) follows:

Host 0 -- ip 10.100.9.87 -- ranks 0 - 3
Host 1 -- ip 10.100.9.94 -- ranks 4 - 7
Host 2 -- ip 10.100.9.95 -- ranks 8 - 11
Host 3 -- ip 10.100.9.96 -- ranks 12 - 15
Host 4 -- ip 10.100.9.57 -- ranks 16 - 19
Host 5 -- ip 10.100.9.61 -- ranks 20 - 23
Host 6 -- ip 10.100.9.63 -- ranks 24 - 27
Host 7 -- ip 10.100.9.64 -- ranks 28 - 31

 host | 0    1    2    3    4    5    6    7
======|=========================================
    0 : SHM  TCP  TCP  TCP  TCP  TCP  TCP  TCP
    1 : TCP  SHM  TCP  TCP  TCP  TCP  TCP  TCP
    2 : TCP  TCP  SHM  TCP  TCP  TCP  TCP  TCP
    3 : TCP  TCP  TCP  SHM  TCP  TCP  TCP  TCP
    4 : TCP  TCP  TCP  TCP  SHM  TCP  TCP  TCP
    5 : TCP  TCP  TCP  TCP  TCP  SHM  TCP  TCP
    6 : TCP  TCP  TCP  TCP  TCP  TCP  SHM  TCP
    7 : TCP  TCP  TCP  TCP  TCP  TCP  TCP  SHM

 Prot -  All Intra-node communication is: SHM
 Prot -  All Inter-node communication is: TCP

Bins: 1000000
Points: 10000000
Nodes: 32
Seed: 123456789
maxLocalNumPoints: 312500
Rank: 17 Bad Points:1
Rank: 20 Bad Points:1

Timing:
Point Generation: 4.603151
Map Generation: 0.037122
Point Binning: 3.712302


PS:

Read file <project_error_file> for stderr output of this job.

Sender: LSF System <lsfadmin@compute-0-131>
Subject: Job 638619: <Teddy-MPI> in cluster <mghpcc_cluster1> Done

Job <Teddy-MPI> was submitted from host <discovery2> by user <stoddard.t> in cluster <mghpcc_cluster1>.
Job was executed on host(s) <4*compute-0-131>, in queue <ser-par-10g-3>, as user <stoddard.t> in cluster <mghpcc_cluster1>.
                            <4*compute-0-132>
</home/stoddard.t> was used as the home directory.
</home/stoddard.t/FibonacciSphere> was used as the working directory.
Started at Wed Apr 13 09:34:41 2016
Results reported at Wed Apr 13 09:34:52 2016

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
#BSUB -J Teddy-MPI
#BSUB -o project_output_file
#BSUB -e project_error_file
#BSUB -n 8
#BSUB -q ser-par-10g-3
#BSUB cwd /home/stoddard.t/FibonacciSphere/
#BSUB -R "span[ptile=4]"
work=/home/stoddard.t/FibonacciSphere/

cd $work
tempfile1=hostlistrun
tempfile2=hostlist-tcp
echo $LSB_MCPU_HOSTS > $tempfile1
declare -a hosts
read -a hosts < ${tempfile1}
for ((i=0; i<${#hosts[@]}; i += 2)) ;
do
  HOST=${hosts[$i]}
  CORE=${hosts[(($i+1))]}
  echo $HOST:$CORE >> $tempfile2
done

mpirun -np 8 -prot -TCP -lsf ./bin/fibonacciSphereMPI 1000000 10000000 123456789

rm $work/$tempfile1
rm $work/$tempfile2
 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :               89.74 sec.
    Max Memory :             14 MB
    Average Memory :         14.00 MB
    Total Requested Memory : -
    Delta Memory :           -
    (Delta: the difference between total requested memory and actual max usage.)
    Max Swap :               57 MB

    Max Processes :          1
    Max Threads :            1

The output (if any) follows:

Host 0 -- ip 10.100.9.88 -- ranks 0 - 3
Host 1 -- ip 10.100.9.89 -- ranks 4 - 7

 host | 0    1
======|===========
    0 : SHM  TCP
    1 : TCP  SHM

 Prot -  All Intra-node communication is: SHM
 Prot -  All Inter-node communication is: TCP

Bins: 1000000
Points: 10000000
Nodes: 8
Seed: 123456789
maxLocalNumPoints: 1250000
Rank: 4 Bad Points:1
Rank: 5 Bad Points:1

Timing:
Point Generation: 3.150045
Map Generation: 0.019562
Point Binning: 7.982908


PS:

Read file <project_error_file> for stderr output of this job.

